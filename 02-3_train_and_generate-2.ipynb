{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.learner import Learner\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.optimizer import Adam\n",
    "from fastai.callback.progress import ProgressCallback\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from parse_preprocessed_data import get_inputs_and_targets\n",
    "from LSTM_Model2 import LSTMModel2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50\n",
    "\n",
    "hidden_size = 128\n",
    "learning_rate = 2e-3\n",
    "dropout = 0.5\n",
    "batch_size = 100\n",
    "num_layers = 3\n",
    "max_epochs = 20\n",
    "validation_prop = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique chars: ['\\n', '-', '<', '>', '?', 'B', 'E', 'Q', 'S', 'X', '[', ']', 'b', 'o', 'x']\n",
      "Number of unique chars: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, (124700, 50, 15), (124700, 50))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not Original\n",
    "char_to_ix, ix_to_char, vocab_size, inputs, targets = get_inputs_and_targets('data_preprocessed/mario.txt', seq_length)\n",
    "vocab_size, inputs.shape, targets.shape\n",
    "\n",
    "#I know these inputs and targets to be correct, as this is the same as the original model\n",
    "#vocab_size is 15\n",
    "#inputs is (num_sequences, sequence_size, vocab_size), and is hot-shot encoded\n",
    "#targets is (num_sequence, sequence_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Original\n",
    "#Unrelated for my issue\n",
    "#first_three_cols = inputs[0][:3 * 17]\n",
    "#np.savetxt('data_preprocessed/seed.txt', first_three_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Original\n",
    "#Unrelated for my issue\n",
    "with open('data_preprocessed/char_to_ix.json', 'w+') as json_f:\n",
    "    json.dump(char_to_ix, json_f)\n",
    "\n",
    "with open('data_preprocessed/ix_to_char.json', 'w+') as json_f:\n",
    "    json.dump(ix_to_char, json_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs.shape, inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets.shape, targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = torch.from_numpy(inputs).type(torch.Tensor).to(device)\n",
    "#targets = torch.from_numpy(targets).type(torch.Tensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute loss as the cross-entropy loss betweenthe predicted values and the true labels\n",
    "def custom_loss(y_pred_tup, y_true):\n",
    "    y_pred,_,_,_,_,_,_ = y_pred_tup\n",
    "    return F.cross_entropy(\n",
    "        y_pred.view(-1, vocab_size),\n",
    "        y_true.long().view(-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essentially tries to compute the accuracy of the predicted sequence to the true sequence\n",
    "def custom_acc(y_pred_tup, y_true):\n",
    "    y_pred,_,_,_,_,_,_ = y_pred_tup\n",
    "    #Calculate predicted classes by taking the argmax along the second dimension\n",
    "    #Reshape the predicted values into a 2D tensor with shape (batch_size * seq_length, vocab_size)\n",
    "    pred_classes = torch.argmax(y_pred.view(-1, vocab_size), dim=1)\n",
    "    # Flatten the true labels\n",
    "    true_classes = y_true.view(-1)\n",
    "    #Compare each element in the sequence, then converting the binary equality value to a float\n",
    "    class_equality = torch.eq(pred_classes, true_classes).float()\n",
    "    #The mean of all of the equality scores is the accuracy\n",
    "    return torch.mean(class_equality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = LSTMModel2(vocab_size, hidden_size, num_layers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.5131\n",
      "Epoch [2/20], Loss: 0.3058\n",
      "Epoch [3/20], Loss: 0.2772\n",
      "Epoch [4/20], Loss: 0.2609\n",
      "Epoch [5/20], Loss: 0.2509\n",
      "Epoch [6/20], Loss: 0.2442\n",
      "Epoch [7/20], Loss: 0.2393\n",
      "Epoch [8/20], Loss: 0.2350\n",
      "Epoch [9/20], Loss: 0.2320\n",
      "Epoch [10/20], Loss: 0.2290\n",
      "Epoch [11/20], Loss: 0.2268\n",
      "Epoch [12/20], Loss: 0.2247\n",
      "Epoch [13/20], Loss: 0.2227\n",
      "Epoch [14/20], Loss: 0.2213\n",
      "Epoch [15/20], Loss: 0.2199\n",
      "Epoch [16/20], Loss: 0.2183\n",
      "Epoch [17/20], Loss: 0.2172\n",
      "Epoch [18/20], Loss: 0.2162\n",
      "Epoch [19/20], Loss: 0.2153\n",
      "Epoch [20/20], Loss: 0.2141\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, _ = model(batch_inputs)\n",
    "        \n",
    "        # Reshape outputs and targets to have the same batch size\n",
    "        outputs_flat = outputs.view(-1, outputs.size(-1))  # Flatten outputs\n",
    "        targets_flat = batch_targets.view(-1)  # Flatten targets\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs_flat, targets_flat.long())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_inputs.size(0)  # Accumulate loss for the entire batch\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = total_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Print epoch-wise loss\n",
    "    print(f'Epoch [{epoch+1}/{max_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Original\n",
    "seed = np.loadtxt('data_preprocessed/seed.txt', dtype=float)[:3*17 - 1].copy()\n",
    "\n",
    "with open('data_preprocessed/ix_to_char.json', 'r') as json_f:\n",
    "    ix_to_char = json.load(json_f)\n",
    "    \n",
    "with open('data_preprocessed/char_to_ix.json', 'r') as json_f:\n",
    "    char_to_ix = json.load(json_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Original\n",
    "def onehot_to_string(onehot):\n",
    "    ints = np.argmax(onehot, axis=-1)\n",
    "    chars = [ix_to_char[str(ix)] for ix in ints]\n",
    "    string = \"\".join(chars)\n",
    "    char_array = []\n",
    "    for line in string.rstrip().split('\\n')[:-1]:\n",
    "        if len(line) == 16:\n",
    "            char_array.append(list(line))\n",
    "        elif len(line) > 16:\n",
    "            char_array.append(list(line[:16]))\n",
    "        elif len(line) < 16:\n",
    "            char_array.append(['-'] * (16 - len(line)) + list(line))\n",
    "    char_array = np.array(char_array).T\n",
    "    string = \"\"\n",
    "    for row in char_array:\n",
    "        string += \"\".join(row) + \"\\n\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "-x\n",
      "XX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Not Original\n",
    "seed[17+14] = 0\n",
    "seed[17+14][char_to_ix['x']] = 1\n",
    "seed[17*2+14] = 0\n",
    "seed[17*2+14][char_to_ix['x']] = 1\n",
    "print(onehot_to_string(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Original\n",
    "def get_seed():\n",
    "    seed = np.loadtxt('data_preprocessed/seed.txt', dtype=float)[:3*17 - 1]\n",
    "    seed[17+14] = 0\n",
    "    seed[17+14][char_to_ix['x']] = 1\n",
    "    seed[17*2+14] = 0\n",
    "    seed[17*2+14][char_to_ix['x']] = 1\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not Original\n",
    "seed = get_seed()\n",
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n"
     ]
    }
   ],
   "source": [
    "#Not Original\n",
    "num_levels_to_gen = 10\n",
    "num_chunks = 10\n",
    "num_cols_per_chunk = 16\n",
    "num_rows_per_col = 17\n",
    "num_chars_to_gen = num_chunks * num_cols_per_chunk * num_rows_per_col - len(seed)\n",
    "print(num_chars_to_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_seed().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hidden states\n",
    "h0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
    "c0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
    "\n",
    "seed = get_seed()\n",
    "seed = np.expand_dims(seed, axis=0)\n",
    "seed = np.repeat(seed, num_levels_to_gen, axis=0)\n",
    "seed.shape\n",
    "\n",
    "gen = []\n",
    "\n",
    "for i in range(num_levels_to_gen):\n",
    "    # Seed initialization\n",
    "    seed = torch.from_numpy(get_seed()).type(torch.Tensor).to(device)\n",
    "    generated_seq = []\n",
    "    h0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
    "    c0 = torch.zeros(num_layers, 1, hidden_size).to(device)\n",
    "    # Generate characters\n",
    "    for j in range(num_chars_to_gen):\n",
    "        # Forward pass through the model\n",
    "        output, (h0, c0) = model(seed.view(1, -1, vocab_size), (h0, c0))\n",
    "        output_probs = F.softmax(output, dim=-1).squeeze().cpu().detach().numpy()\n",
    "    \n",
    "        # Sample the next character\n",
    "        next_char_idx = np.random.choice(vocab_size, p=output_probs[-1])\n",
    "        next_char = ix_to_char[str(next_char_idx)]\n",
    "        generated_seq.append(next_char)\n",
    "        \n",
    "        # Update the seed for the next iteration\n",
    "        #seed = torch.cat((seed[1:], F.one_hot(torch.tensor(next_char_idx), num_classes=vocab_size).unsqueeze(0)), dim=0).to(device)\n",
    "        next_char_tensor = torch.tensor(next_char_idx).to(device)\n",
    "        one_hot_tensor = F.one_hot(next_char_tensor, num_classes=vocab_size).unsqueeze(0).to(device)\n",
    "        seed = torch.cat((seed[1:].to(device), one_hot_tensor), dim=0)\n",
    "        \n",
    "    # Convert generated sequence to a string\n",
    "    generated_str = ''.join(generated_seq)\n",
    "    gen.append(generated_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n-------------xxX\\n-------------xEX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n------S---S--xXX\\n------S--ES--xXX\\n------S---S--xXX\\n------S---?--xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n------------xxXX\\n-----------xx-XX\\n----------xx----\\n----------xX----\\n-------X-xxX----\\n-------X-x-E----\\n-------X-x-E----\\n-------X-x-X----\\n----------xX----\\n----------xX----\\n----------xX----\\n----------xX----\\n----------xX----\\n---------xxX----\\n--------xx------\\n--------x-------\\n--------x-------\\n-------ExxX-----\\n-------xxX------\\n------xx--------\\n-----xx---------\\n-----x-E-------X\\n-----x----------\\n------x---------\\n-------x--------\\n--------x-------\\n---------x-Q----\\n---------x------\\n----------x-----\\n-----------x----\\n------------x---\\n-------------xX-\\n-------------xX-\\n-------------xx-\\n-------------xxX\\n------------xxXX\\n-----------xxEXX\\n----------xx--XX\\n---------xx---XX\\n---------x<[[[XX\\n---------x>]]]XX\\n---------x----XX\\n----------x---XX\\n-----------x--XX\\n------------x-XX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n-------------xXX\\n--------<[X--xXX\\n-------E>]Q--xXX\\n----------Q--xXX\\n----------Q--xXX\\n----------Q--xXX\\n----------Q--xXX\\n----------Q-xxXX\\n-----------xxXXX\\n----------xxXXXX\\n---------xxXXXXX\\n---------xXXXXXX\\n---------xS----X\\n---------x-----X\\n----------x----X\\n-------o---x---X\\n-------o----x--X\\n-------o-----x-X\\n-------o------xX\\n-------E------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n-------------xxX\\n-------------x--\\n-------------x-X\\n-------------x-X\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n-------------xxX\\n------------xx-X\\n-----------xx--X\\n-----------x<[[X\\n-----------x>]]X\\n-----------x---X\\n------------x--X\\n-------------x-X\\n--------------xX\\n-------------xxX\\n------------xx-X\\n-----------xx--X\\n----------xx---X\\n----------xX----\\n---------xxX----\\n--------xx------\\n-------xx------X\\n-------x-------X\\n-------x-------X\\n--------x-----EX\\n---------x-----X\\n----------x----X\\n-----------x---X\\n------------x--X\\n-------------xEX\\n--------------xX\\n-------------ExX\\n-------------xxX\\n-----------S-x--\\n-----------?-x-X\\n-------------x--\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n-------------BxX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n--------------xX\\n'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_gen = []\n",
    "for i in range(len(gen)):\n",
    "    rows = gen[i].split('\\n')[1:-1]\n",
    "    for r in range(len(rows)):\n",
    "        row = rows[r]\n",
    "        # Pad the row with 'x' until it reaches length 16\n",
    "        rows[r] = row.ljust(16, 'x')\n",
    "    new_string = ''\n",
    "    for j in range(16):\n",
    "        new_string = new_string + ''.join([row[j] for row in rows])\n",
    "        if j < 15:\n",
    "            new_string += '\\n'\n",
    "    modified_gen.append(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Original\n",
    "for i, g in enumerate(modified_gen):\n",
    "    with open(f'generated_levels_txt/{i+1}.txt', 'w+') as txt_f:\n",
    "        txt_f.write(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
